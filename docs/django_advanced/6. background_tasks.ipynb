{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2b0b47",
   "metadata": {},
   "source": [
    "## Background Tasks in Django\n",
    "Background tasks in Django allow you to execute time-consuming operations asynchronously, improving application performance and user experience. Instead of making users wait for long-running processes to complete, you can offload these tasks to run in the background.\n",
    "\n",
    "### Why Use Background Tasks?\n",
    "- **Improved Performance**: Prevent blocking of web requests\n",
    "- **Better User Experience**: Users don't have to wait for long operations\n",
    "- **Resource Management**: Distribute workload across multiple workers\n",
    "- **Reliability**: Tasks can be retried if they fail\n",
    "\n",
    "### Common Use Cases\n",
    "- Sending emails\n",
    "- Processing uploaded files\n",
    "- Data synchronization\n",
    "- Report generation\n",
    "- API calls to external services\n",
    "- Database maintenance tasks\n",
    "\n",
    "### Available Solutions\n",
    "Django doesn't include built-in background task processing, but several excellent third-party libraries are available:\n",
    "- **Celery**: Most popular, feature-rich, supports multiple brokers\n",
    "- **Django-Q**: Lightweight, uses Django ORM as message broker\n",
    "- **Huey**: Simple, supports Redis and SQLite\n",
    "- **Django Background Tasks**: Simple database-backed task queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bf3cf",
   "metadata": {},
   "source": [
    "## Setting Up Celery with Django\n",
    "Celery is the most popular background task library for Django. It supports multiple message brokers (Redis, RabbitMQ) and result backends.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install celery[redis]\n",
    "```\n",
    "\n",
    "### Configuration\n",
    "Create `celery.py` in your Django project root:\n",
    "\n",
    "```python\n",
    "# celery.py\n",
    "import os\n",
    "from celery import Celery\n",
    "from django.conf import settings\n",
    "\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'yourproject.settings')\n",
    "\n",
    "app = Celery('yourproject')\n",
    "app.config_from_object('django.conf:settings', namespace='CELERY')\n",
    "app.autodiscover_tasks()\n",
    "\n",
    "@app.task(bind=True)\n",
    "def debug_task(self):\n",
    "    print(f'Request: {self.request!r}')\n",
    "```\n",
    "\n",
    "Update `__init__.py`:\n",
    "```python\n",
    "# __init__.py\n",
    "from .celery import app as celery_app\n",
    "\n",
    "__all__ = ('celery_app',)\n",
    "```\n",
    "\n",
    "Add to `settings.py`:\n",
    "```python\n",
    "# settings.py\n",
    "CELERY_BROKER_URL = 'redis://localhost:6379/0'\n",
    "CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'\n",
    "CELERY_ACCEPT_CONTENT = ['json']\n",
    "CELERY_TASK_SERIALIZER = 'json'\n",
    "CELERY_RESULT_SERIALIZER = 'json'\n",
    "CELERY_TIMEZONE = 'UTC'\n",
    "```\n",
    "\n",
    "### Creating Tasks\n",
    "Create `tasks.py` in your app:\n",
    "\n",
    "```python\n",
    "# tasks.py\n",
    "from celery import shared_task\n",
    "from django.core.mail import send_mail\n",
    "from .models import Report\n",
    "\n",
    "@shared_task\n",
    "def send_welcome_email(user_email):\n",
    "    send_mail(\n",
    "        'Welcome!',\n",
    "        'Thank you for joining our platform.',\n",
    "        'noreply@example.com',\n",
    "        [user_email],\n",
    "        fail_silently=False,\n",
    "    )\n",
    "    return f'Email sent to {user_email}'\n",
    "\n",
    "@shared_task\n",
    "def generate_report(report_id):\n",
    "    report = Report.objects.get(id=report_id)\n",
    "    # Generate report logic here\n",
    "    report.status = 'completed'\n",
    "    report.save()\n",
    "    return f'Report {report_id} generated'\n",
    "```\n",
    "\n",
    "### Running Celery\n",
    "```bash\n",
    "# Start worker\n",
    "celery -A yourproject worker -l info\n",
    "\n",
    "# Start beat (for periodic tasks)\n",
    "celery -A yourproject beat -l info\n",
    "```\n",
    "\n",
    "### Using Tasks in Views\n",
    "```python\n",
    "# views.py\n",
    "from .tasks import send_welcome_email, generate_report\n",
    "\n",
    "def register_user(request):\n",
    "    # User creation logic\n",
    "    user = User.objects.create(...)\n",
    "    \n",
    "    # Send welcome email asynchronously\n",
    "    send_welcome_email.delay(user.email)\n",
    "    \n",
    "    return JsonResponse({'message': 'User registered'})\n",
    "\n",
    "def create_report(request):\n",
    "    report = Report.objects.create(status='pending')\n",
    "    \n",
    "    # Generate report asynchronously\n",
    "    generate_report.delay(report.id)\n",
    "    \n",
    "    return JsonResponse({'report_id': report.id})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c08fe",
   "metadata": {},
   "source": [
    "## Django-Q\n",
    "Django-Q is a lightweight task queue that uses Django's ORM as the message broker, making it easy to set up without external dependencies.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install django-q\n",
    "```\n",
    "\n",
    "### Configuration\n",
    "Add to `settings.py`:\n",
    "```python\n",
    "# settings.py\n",
    "INSTALLED_APPS = [\n",
    "    # ...\n",
    "    'django_q',\n",
    "]\n",
    "\n",
    "Q_CLUSTER = {\n",
    "    'name': 'yourproject',\n",
    "    'workers': 4,\n",
    "    'recycle': 500,\n",
    "    'timeout': 60,\n",
    "    'compress': True,\n",
    "    'save_limit': 250,\n",
    "    'queue_limit': 500,\n",
    "    'cpu_affinity': 1,\n",
    "    'label': 'Django Q',\n",
    "    'redis': {\n",
    "        'host': '127.0.0.1',\n",
    "        'port': 6379,\n",
    "        'db': 0,\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Creating Tasks\n",
    "```python\n",
    "# tasks.py\n",
    "from django_q.tasks import async_task\n",
    "from django.core.mail import send_mail\n",
    "\n",
    "def send_notification(user_id, message):\n",
    "    user = User.objects.get(id=user_id)\n",
    "    send_mail(\n",
    "        'Notification',\n",
    "        message,\n",
    "        'noreply@example.com',\n",
    "        [user.email],\n",
    "    )\n",
    "\n",
    "def process_uploaded_file(file_id):\n",
    "    uploaded_file = UploadedFile.objects.get(id=file_id)\n",
    "    # Process file logic\n",
    "    uploaded_file.processed = True\n",
    "    uploaded_file.save()\n",
    "```\n",
    "\n",
    "### Using Tasks\n",
    "```python\n",
    "# views.py\n",
    "from django_q.tasks import async_task\n",
    "from .tasks import send_notification, process_uploaded_file\n",
    "\n",
    "def upload_file(request):\n",
    "    file_obj = UploadedFile.objects.create(file=request.FILES['file'])\n",
    "    \n",
    "    # Process file asynchronously\n",
    "    async_task(process_uploaded_file, file_obj.id)\n",
    "    \n",
    "    return JsonResponse({'file_id': file_obj.id})\n",
    "\n",
    "def send_user_notification(request):\n",
    "    user_id = request.POST.get('user_id')\n",
    "    message = request.POST.get('message')\n",
    "    \n",
    "    # Send notification asynchronously\n",
    "    async_task(send_notification, user_id, message)\n",
    "    \n",
    "    return JsonResponse({'status': 'Notification queued'})\n",
    "```\n",
    "\n",
    "### Running Django-Q\n",
    "```bash\n",
    "# Run migrations\n",
    "python manage.py migrate\n",
    "\n",
    "# Start cluster\n",
    "python manage.py qcluster\n",
    "\n",
    "# Monitor tasks\n",
    "python manage.py qmonitor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb2131",
   "metadata": {},
   "source": [
    "## Huey\n",
    "Huey is a lightweight task queue that supports Redis and SQLite backends. It's simple to set up and use.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install huey[redis]\n",
    "```\n",
    "\n",
    "### Configuration\n",
    "Create `huey_config.py`:\n",
    "```python\n",
    "# huey_config.py\n",
    "from huey import RedisHuey\n",
    "\n",
    "huey = RedisHuey('my-app', host='localhost')\n",
    "```\n",
    "\n",
    "### Creating Tasks\n",
    "```python\n",
    "# tasks.py\n",
    "from huey_config import huey\n",
    "from django.core.mail import send_mail\n",
    "\n",
    "@huey.task()\n",
    "def send_email_task(recipient, subject, message):\n",
    "    send_mail(subject, message, 'noreply@example.com', [recipient])\n",
    "    return f'Email sent to {recipient}'\n",
    "\n",
    "@huey.task()\n",
    "def process_data_task(data_id):\n",
    "    data = Data.objects.get(id=data_id)\n",
    "    # Process data\n",
    "    data.processed = True\n",
    "    data.save()\n",
    "    return f'Data {data_id} processed'\n",
    "\n",
    "# Periodic tasks\n",
    "@huey.periodic_task(crontab(minute='0', hour='*/2'))\n",
    "def cleanup_old_data():\n",
    "    # Clean up old data every 2 hours\n",
    "    old_data = Data.objects.filter(created_at__lt=timezone.now() - timedelta(days=30))\n",
    "    old_data.delete()\n",
    "    return f'Cleaned up {old_data.count()} old records'\n",
    "```\n",
    "\n",
    "### Using Tasks\n",
    "```python\n",
    "# views.py\n",
    "from .tasks import send_email_task, process_data_task\n",
    "\n",
    "def contact_form(request):\n",
    "    # Process form\n",
    "    send_email_task('admin@example.com', 'New Contact', request.POST['message'])\n",
    "    return JsonResponse({'status': 'Message sent'})\n",
    "\n",
    "def upload_data(request):\n",
    "    data = Data.objects.create(raw_data=request.POST['data'])\n",
    "    process_data_task(data.id)\n",
    "    return JsonResponse({'data_id': data.id})\n",
    "```\n",
    "\n",
    "### Running Huey\n",
    "```bash\n",
    "# Start consumer\n",
    "python manage.py run_huey\n",
    "```\n",
    "\n",
    "### Django Integration\n",
    "Create a management command for running Huey:\n",
    "```python\n",
    "# management/commands/run_huey.py\n",
    "from django.core.management.base import BaseCommand\n",
    "from huey_config import huey\n",
    "\n",
    "class Command(BaseCommand):\n",
    "    def handle(self, *args, **options):\n",
    "        huey.start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112e4be",
   "metadata": {},
   "source": [
    "## Django Background Tasks\n",
    "Django Background Tasks is a simple database-backed task queue that doesn't require external dependencies.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install django-background-tasks\n",
    "```\n",
    "\n",
    "### Configuration\n",
    "Add to `settings.py`:\n",
    "```python\n",
    "INSTALLED_APPS = [\n",
    "    # ...\n",
    "    'background_task',\n",
    "]\n",
    "\n",
    "# Optional: Configure task storage\n",
    "BACKGROUND_TASK_RUN_ASYNC = True\n",
    "```\n",
    "\n",
    "### Creating Tasks\n",
    "```python\n",
    "# tasks.py\n",
    "from background_task import background\n",
    "from django.core.mail import send_mail\n",
    "\n",
    "@background(schedule=60)  # Run 60 seconds after creation\n",
    "def send_email_later(email, subject, message):\n",
    "    send_mail(subject, message, 'noreply@example.com', [email])\n",
    "\n",
    "@background\n",
    "def process_image(image_id):\n",
    "    image = Image.objects.get(id=image_id)\n",
    "    # Process image\n",
    "    image.processed = True\n",
    "    image.save()\n",
    "\n",
    "# Repeatable tasks\n",
    "@background(schedule=3600, repeat=3600)  # Every hour\n",
    "def hourly_cleanup():\n",
    "    # Clean up temporary files\n",
    "    pass\n",
    "```\n",
    "\n",
    "### Using Tasks\n",
    "```python\n",
    "# views.py\n",
    "from .tasks import send_email_later, process_image\n",
    "\n",
    "def schedule_email(request):\n",
    "    # Schedule email to be sent in 1 hour\n",
    "    send_email_later(\n",
    "        request.POST['email'],\n",
    "        'Scheduled Email',\n",
    "        'This email was scheduled',\n",
    "        schedule=3600  # Override default schedule\n",
    "    )\n",
    "    return JsonResponse({'status': 'Email scheduled'})\n",
    "\n",
    "def upload_image(request):\n",
    "    image = Image.objects.create(image_file=request.FILES['image'])\n",
    "    process_image.now(image.id)  # Run immediately\n",
    "    return JsonResponse({'image_id': image.id})\n",
    "```\n",
    "\n",
    "### Running Tasks\n",
    "```bash\n",
    "# Run migrations\n",
    "python manage.py migrate\n",
    "\n",
    "# Process tasks\n",
    "python manage.py process_tasks\n",
    "```\n",
    "\n",
    "### Admin Interface\n",
    "Django Background Tasks provides an admin interface to view and manage tasks:\n",
    "```python\n",
    "# admin.py\n",
    "from django.contrib import admin\n",
    "from background_task.models import Task\n",
    "\n",
    "admin.site.register(Task)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e064e6",
   "metadata": {},
   "source": [
    "## Best Practices for Background Tasks\n",
    "\n",
    "### 1. Task Design\n",
    "- **Keep tasks simple**: Each task should do one thing well\n",
    "- **Make tasks idempotent**: Tasks should be safe to run multiple times\n",
    "- **Use appropriate timeouts**: Prevent tasks from running indefinitely\n",
    "- **Handle failures gracefully**: Implement retry logic and error handling\n",
    "\n",
    "### 2. Error Handling and Retries\n",
    "```python\n",
    "# Celery example\n",
    "@shared_task(bind=True, max_retries=3)\n",
    "def robust_task(self):\n",
    "    try:\n",
    "        # Task logic\n",
    "        risky_operation()\n",
    "    except Exception as exc:\n",
    "        # Retry with exponential backoff\n",
    "        self.retry(countdown=2 ** self.request.retries, exc=exc)\n",
    "```\n",
    "\n",
    "### 3. Monitoring and Logging\n",
    "- **Log task execution**: Track when tasks start, succeed, or fail\n",
    "- **Monitor queue length**: Alert when queues get too long\n",
    "- **Track performance**: Monitor task execution times\n",
    "- **Set up alerts**: Get notified of task failures\n",
    "\n",
    "### 4. Resource Management\n",
    "- **Limit concurrent tasks**: Prevent resource exhaustion\n",
    "- **Use appropriate worker counts**: Match workers to available resources\n",
    "- **Implement rate limiting**: Prevent overwhelming external APIs\n",
    "- **Clean up old tasks**: Remove completed tasks from storage\n",
    "\n",
    "### 5. Testing Background Tasks\n",
    "- **Test tasks synchronously**: Use `.delay()` vs direct function calls\n",
    "- **Mock external dependencies**: Isolate task logic\n",
    "- **Test error scenarios**: Ensure proper error handling\n",
    "- **Verify task scheduling**: Test periodic and delayed tasks\n",
    "\n",
    "### 6. Security Considerations\n",
    "- **Validate input data**: Don't trust data passed to tasks\n",
    "- **Use secure connections**: Encrypt communication with brokers\n",
    "- **Limit task permissions**: Run tasks with minimal privileges\n",
    "- **Audit task execution**: Log who triggered tasks\n",
    "\n",
    "### 7. Performance Optimization\n",
    "- **Batch operations**: Group similar tasks together\n",
    "- **Use appropriate data structures**: Choose efficient storage\n",
    "- **Optimize database queries**: Use select_related/prefetch_related\n",
    "- **Cache frequently used data**: Reduce database hits\n",
    "\n",
    "### 8. Deployment Considerations\n",
    "- **Scale workers horizontally**: Add more worker processes\n",
    "- **Use load balancers**: Distribute tasks across multiple servers\n",
    "- **Implement health checks**: Monitor worker and broker health\n",
    "- **Plan for zero-downtime deployments**: Graceful worker shutdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e68e0",
   "metadata": {},
   "source": [
    "## Testing Background Tasks\n",
    "\n",
    "### Testing with Celery\n",
    "```python\n",
    "# tests.py\n",
    "from django.test import TestCase\n",
    "from unittest.mock import patch, MagicMock\n",
    "from .tasks import send_welcome_email\n",
    "\n",
    "class TaskTestCase(TestCase):\n",
    "    @patch('myapp.tasks.send_mail')\n",
    "    def test_send_welcome_email(self, mock_send_mail):\n",
    "        # Test task logic\n",
    "        result = send_welcome_email('test@example.com')\n",
    "        \n",
    "        mock_send_mail.assert_called_once()\n",
    "        self.assertEqual(result, 'Email sent to test@example.com')\n",
    "    \n",
    "    def test_send_welcome_email_async(self):\n",
    "        # Test async execution\n",
    "        from django.test.utils import override_settings\n",
    "        \n",
    "        with override_settings(CELERY_ALWAYS_EAGER=True):\n",
    "            result = send_welcome_email.delay('test@example.com')\n",
    "            self.assertTrue(result.successful())\n",
    "```\n",
    "\n",
    "### Testing with Django-Q\n",
    "```python\n",
    "# tests.py\n",
    "from django.test import TestCase\n",
    "from django_q.tasks import async_task\n",
    "from unittest.mock import patch\n",
    "\n",
    "class DjangoQTaskTest(TestCase):\n",
    "    @patch('myapp.tasks.send_notification')\n",
    "    def test_async_task_execution(self, mock_task):\n",
    "        # Test task scheduling\n",
    "        async_task('myapp.tasks.send_notification', 1, 'Hello')\n",
    "        \n",
    "        # In test environment, tasks run synchronously\n",
    "        mock_task.assert_called_once_with(1, 'Hello')\n",
    "```\n",
    "\n",
    "### Testing Periodic Tasks\n",
    "```python\n",
    "# tests.py\n",
    "from django.test import TestCase\n",
    "from django.utils import timezone\n",
    "from datetime import timedelta\n",
    "from .tasks import cleanup_old_data\n",
    "\n",
    "class PeriodicTaskTest(TestCase):\n",
    "    def setUp(self):\n",
    "        # Create test data\n",
    "        self.old_data = Data.objects.create(\n",
    "            created_at=timezone.now() - timedelta(days=40)\n",
    "        )\n",
    "        self.new_data = Data.objects.create(\n",
    "            created_at=timezone.now()\n",
    "        )\n",
    "    \n",
    "    def test_cleanup_old_data(self):\n",
    "        # Run cleanup task\n",
    "        result = cleanup_old_data()\n",
    "        \n",
    "        # Check that old data was deleted\n",
    "        self.assertFalse(Data.objects.filter(id=self.old_data.id).exists())\n",
    "        self.assertTrue(Data.objects.filter(id=self.new_data.id).exists())\n",
    "        self.assertIn('1', result)  # Should mention 1 record cleaned up\n",
    "```\n",
    "\n",
    "### Integration Testing\n",
    "```python\n",
    "# tests.py\n",
    "from django.test import TestCase, override_settings\n",
    "from django.core import mail\n",
    "from .models import User\n",
    "\n",
    "class BackgroundTaskIntegrationTest(TestCase):\n",
    "    @override_settings(CELERY_ALWAYS_EAGER=True)\n",
    "    def test_user_registration_sends_email(self):\n",
    "        # Create user (which triggers background email)\n",
    "        user = User.objects.create_user('test@example.com', 'password')\n",
    "        \n",
    "        # Check that email was sent\n",
    "        self.assertEqual(len(mail.outbox), 1)\n",
    "        self.assertEqual(mail.outbox[0].to, ['test@example.com'])\n",
    "        self.assertEqual(mail.outbox[0].subject, 'Welcome!')\n",
    "```\n",
    "\n",
    "### Testing Task Failure Scenarios\n",
    "```python\n",
    "# tests.py\n",
    "from django.test import TestCase\n",
    "from unittest.mock import patch\n",
    "from .tasks import process_payment\n",
    "\n",
    "class TaskFailureTest(TestCase):\n",
    "    @patch('payment_service.charge_card')\n",
    "    def test_payment_failure_handling(self, mock_charge):\n",
    "        # Simulate payment failure\n",
    "        mock_charge.side_effect = Exception('Payment declined')\n",
    "        \n",
    "        # Task should handle the exception gracefully\n",
    "        with self.assertRaises(Exception):\n",
    "            process_payment('card_token', 100)\n",
    "        \n",
    "        # Verify error was logged or handled appropriately\n",
    "        # Check that payment status was updated to failed\n",
    "```\n",
    "\n",
    "### Performance Testing\n",
    "```python\n",
    "# tests.py\n",
    "from django.test import TestCase\n",
    "from django.test.utils import override_settings\n",
    "import time\n",
    "\n",
    "class TaskPerformanceTest(TestCase):\n",
    "    @override_settings(CELERY_ALWAYS_EAGER=True)\n",
    "    def test_task_execution_time(self):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Execute task\n",
    "        result = heavy_computation_task.delay()\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Assert task completed within reasonable time\n",
    "        self.assertLess(execution_time, 5.0)  # Less than 5 seconds\n",
    "        self.assertTrue(result.successful())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc786c5",
   "metadata": {},
   "source": [
    "## Performance Considerations and Monitoring\n",
    "\n",
    "### Performance Optimization\n",
    "- **Task Chunking**: Break large tasks into smaller chunks\n",
    "- **Priority Queues**: Use different queues for different priority tasks\n",
    "- **Worker Pool Sizing**: Match worker count to available resources\n",
    "- **Connection Pooling**: Reuse database connections\n",
    "- **Memory Management**: Monitor memory usage of long-running tasks\n",
    "\n",
    "### Monitoring Tools\n",
    "\n",
    "#### Celery Monitoring\n",
    "```python\n",
    "# settings.py\n",
    "CELERY_SEND_EVENTS = True\n",
    "CELERY_SEND_TASK_EVENTS = True\n",
    "\n",
    "# Install Flower for monitoring\n",
    "# pip install flower\n",
    "# celery -A yourproject flower\n",
    "```\n",
    "\n",
    "#### Django-Q Monitoring\n",
    "Django-Q provides built-in monitoring:\n",
    "```python\n",
    "# Access via admin or custom views\n",
    "from django_q.monitor import Stat\n",
    "\n",
    "def task_stats(request):\n",
    "    stat = Stat.get_all()\n",
    "    return JsonResponse(stat)\n",
    "```\n",
    "\n",
    "#### Custom Monitoring\n",
    "```python\n",
    "# middleware.py\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TaskMonitoringMiddleware:\n",
    "    def __init__(self, get_response):\n",
    "        self.get_response = get_response\n",
    "    \n",
    "    def __call__(self, request):\n",
    "        start_time = time.time()\n",
    "        response = self.get_response(request)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        logger.info(f'Request to {request.path} took {duration:.2f}s')\n",
    "        return response\n",
    "```\n",
    "\n",
    "### Error Handling and Recovery\n",
    "- **Circuit Breakers**: Stop calling failing services\n",
    "- **Dead Letter Queues**: Store failed tasks for later analysis\n",
    "- **Exponential Backoff**: Increase retry delays\n",
    "- **Manual Intervention**: Allow manual retry of failed tasks\n",
    "\n",
    "### Scaling Strategies\n",
    "\n",
    "#### Horizontal Scaling\n",
    "```bash\n",
    "# Run multiple workers\n",
    "celery -A yourproject worker --pool=prefork --concurrency=4 -n worker1@%h\n",
    "celery -A yourproject worker --pool=prefork --concurrency=4 -n worker2@%h\n",
    "```\n",
    "\n",
    "#### Vertical Scaling\n",
    "- Increase worker memory and CPU allocation\n",
    "- Use faster storage (SSD, Redis clusters)\n",
    "- Optimize database queries in tasks\n",
    "\n",
    "### Common Performance Pitfalls\n",
    "1. **Memory Leaks**: Tasks that don't release resources\n",
    "2. **Database Connection Exhaustion**: Too many concurrent DB connections\n",
    "3. **Large Task Payloads**: Sending huge data through queues\n",
    "4. **Synchronous Operations**: Blocking calls in async tasks\n",
    "5. **Improper Error Handling**: Tasks that fail silently\n",
    "\n",
    "### Health Checks\n",
    "```python\n",
    "# views.py\n",
    "from django.http import JsonResponse\n",
    "from django_q.monitor import Stat\n",
    "\n",
    "def health_check(request):\n",
    "    try:\n",
    "        # Check database\n",
    "        from django.db import connection\n",
    "        connection.cursor()\n",
    "        \n",
    "        # Check task queue\n",
    "        stat = Stat.get_all()\n",
    "        \n",
    "        return JsonResponse({\n",
    "            'status': 'healthy',\n",
    "            'database': 'ok',\n",
    "            'tasks': stat\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return JsonResponse({\n",
    "            'status': 'unhealthy',\n",
    "            'error': str(e)\n",
    "        }, status=500)\n",
    "```\n",
    "\n",
    "### Logging and Alerting\n",
    "```python\n",
    "# settings.py\n",
    "LOGGING = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'handlers': {\n",
    "        'task_file': {\n",
    "            'level': 'INFO',\n",
    "            'class': 'logging.FileHandler',\n",
    "            'filename': 'logs/tasks.log',\n",
    "        },\n",
    "    },\n",
    "    'loggers': {\n",
    "        'celery.task': {\n",
    "            'handlers': ['task_file'],\n",
    "            'level': 'INFO',\n",
    "            'propagate': False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "### Metrics Collection\n",
    "```python\n",
    "# tasks.py\n",
    "from django.core.cache import cache\n",
    "import time\n",
    "\n",
    "@shared_task\n",
    "def monitored_task():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Task logic\n",
    "        result = do_work()\n",
    "        \n",
    "        # Record success metrics\n",
    "        execution_time = time.time() - start_time\n",
    "        cache.incr('tasks_completed')\n",
    "        cache.rpush('task_times', execution_time)\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # Record failure metrics\n",
    "        cache.incr('tasks_failed')\n",
    "        raise\n",
    "```\n",
    "\n",
    "### Capacity Planning\n",
    "- **Monitor Queue Depth**: Alert when queues grow too long\n",
    "- **Track Throughput**: Measure tasks completed per minute/hour\n",
    "- **Resource Utilization**: Monitor CPU, memory, and disk usage\n",
    "- **Predict Scaling Needs**: Use historical data to plan capacity\n",
    "\n",
    "### Backup and Recovery\n",
    "- **Task Persistence**: Ensure tasks survive restarts\n",
    "- **Data Backup**: Regular backups of task data\n",
    "- **Failover**: Automatic failover to backup workers\n",
    "- **Disaster Recovery**: Plan for complete system failure"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
